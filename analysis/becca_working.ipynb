{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rweng/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rweng/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/rweng/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    }
   ],
   "source": [
    "model_sc = torch.hub.load('huggingface/pytorch-transformers', 'modelForSequenceClassification', 'bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qa_id', 'question_title', 'question_body', 'question_user_name',\n",
       "       'question_user_page', 'answer', 'answer_user_name', 'answer_user_page',\n",
       "       'url', 'category', 'host', 'question_asker_intent_understanding',\n",
       "       'question_body_critical', 'question_conversational',\n",
       "       'question_expect_short_answer', 'question_fact_seeking',\n",
       "       'question_has_commonly_accepted_answer',\n",
       "       'question_interestingness_others', 'question_interestingness_self',\n",
       "       'question_multi_intent', 'question_not_really_a_question',\n",
       "       'question_opinion_seeking', 'question_type_choice',\n",
       "       'question_type_compare', 'question_type_consequence',\n",
       "       'question_type_definition', 'question_type_entity',\n",
       "       'question_type_instructions', 'question_type_procedure',\n",
       "       'question_type_reason_explanation', 'question_type_spelling',\n",
       "       'question_well_written', 'answer_helpful',\n",
       "       'answer_level_of_information', 'answer_plausible', 'answer_relevance',\n",
       "       'answer_satisfaction', 'answer_type_instructions',\n",
       "       'answer_type_procedure', 'answer_type_reason_explanation',\n",
       "       'answer_well_written'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "      <td>6079.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4829.665899</td>\n",
       "      <td>0.892663</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>0.057301</td>\n",
       "      <td>0.698525</td>\n",
       "      <td>0.772633</td>\n",
       "      <td>0.793689</td>\n",
       "      <td>0.587478</td>\n",
       "      <td>0.507275</td>\n",
       "      <td>0.238745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799931</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.654823</td>\n",
       "      <td>0.960054</td>\n",
       "      <td>0.968626</td>\n",
       "      <td>0.854680</td>\n",
       "      <td>0.479547</td>\n",
       "      <td>0.130641</td>\n",
       "      <td>0.502468</td>\n",
       "      <td>0.908254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2789.689555</td>\n",
       "      <td>0.132047</td>\n",
       "      <td>0.219470</td>\n",
       "      <td>0.182196</td>\n",
       "      <td>0.350938</td>\n",
       "      <td>0.303023</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>0.185987</td>\n",
       "      <td>0.335057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.178420</td>\n",
       "      <td>0.114836</td>\n",
       "      <td>0.107666</td>\n",
       "      <td>0.086926</td>\n",
       "      <td>0.074631</td>\n",
       "      <td>0.130743</td>\n",
       "      <td>0.422921</td>\n",
       "      <td>0.225718</td>\n",
       "      <td>0.407097</td>\n",
       "      <td>0.100708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2389.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4847.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7222.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9647.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             qa_id  question_asker_intent_understanding  \\\n",
       "count  6079.000000                          6079.000000   \n",
       "mean   4829.665899                             0.892663   \n",
       "std    2789.689555                             0.132047   \n",
       "min       0.000000                             0.333333   \n",
       "25%    2389.000000                             0.777778   \n",
       "50%    4847.000000                             0.888889   \n",
       "75%    7222.000000                             1.000000   \n",
       "max    9647.000000                             1.000000   \n",
       "\n",
       "       question_body_critical  question_conversational  \\\n",
       "count             6079.000000              6079.000000   \n",
       "mean                 0.595301                 0.057301   \n",
       "std                  0.219470                 0.182196   \n",
       "min                  0.333333                 0.000000   \n",
       "25%                  0.444444                 0.000000   \n",
       "50%                  0.555556                 0.000000   \n",
       "75%                  0.777778                 0.000000   \n",
       "max                  1.000000                 1.000000   \n",
       "\n",
       "       question_expect_short_answer  question_fact_seeking  \\\n",
       "count                   6079.000000            6079.000000   \n",
       "mean                       0.698525               0.772633   \n",
       "std                        0.350938               0.303023   \n",
       "min                        0.000000               0.000000   \n",
       "25%                        0.500000               0.666667   \n",
       "50%                        0.666667               1.000000   \n",
       "75%                        1.000000               1.000000   \n",
       "max                        1.000000               1.000000   \n",
       "\n",
       "       question_has_commonly_accepted_answer  question_interestingness_others  \\\n",
       "count                            6079.000000                      6079.000000   \n",
       "mean                                0.793689                         0.587478   \n",
       "std                                 0.336622                         0.135900   \n",
       "min                                 0.000000                         0.333333   \n",
       "25%                                 0.666667                         0.444444   \n",
       "50%                                 1.000000                         0.555556   \n",
       "75%                                 1.000000                         0.666667   \n",
       "max                                 1.000000                         1.000000   \n",
       "\n",
       "       question_interestingness_self  question_multi_intent  ...  \\\n",
       "count                    6079.000000            6079.000000  ...   \n",
       "mean                        0.507275               0.238745  ...   \n",
       "std                         0.185987               0.335057  ...   \n",
       "min                         0.333333               0.000000  ...   \n",
       "25%                         0.333333               0.000000  ...   \n",
       "50%                         0.444444               0.000000  ...   \n",
       "75%                         0.666667               0.333333  ...   \n",
       "max                         1.000000               1.000000  ...   \n",
       "\n",
       "       question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "count            6079.000000     6079.000000                  6079.000000   \n",
       "mean                0.799931        0.925408                     0.654823   \n",
       "std                 0.178420        0.114836                     0.107666   \n",
       "min                 0.333333        0.333333                     0.333333   \n",
       "25%                 0.666667        0.888889                     0.666667   \n",
       "50%                 0.833333        1.000000                     0.666667   \n",
       "75%                 1.000000        1.000000                     0.666667   \n",
       "max                 1.000000        1.000000                     1.000000   \n",
       "\n",
       "       answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "count       6079.000000       6079.000000          6079.000000   \n",
       "mean           0.960054          0.968626             0.854680   \n",
       "std            0.086926          0.074631             0.130743   \n",
       "min            0.333333          0.333333             0.200000   \n",
       "25%            1.000000          1.000000             0.800000   \n",
       "50%            1.000000          1.000000             0.866667   \n",
       "75%            1.000000          1.000000             0.933333   \n",
       "max            1.000000          1.000000             1.000000   \n",
       "\n",
       "       answer_type_instructions  answer_type_procedure  \\\n",
       "count               6079.000000            6079.000000   \n",
       "mean                   0.479547               0.130641   \n",
       "std                    0.422921               0.225718   \n",
       "min                    0.000000               0.000000   \n",
       "25%                    0.000000               0.000000   \n",
       "50%                    0.500000               0.000000   \n",
       "75%                    1.000000               0.333333   \n",
       "max                    1.000000               1.000000   \n",
       "\n",
       "       answer_type_reason_explanation  answer_well_written  \n",
       "count                     6079.000000          6079.000000  \n",
       "mean                         0.502468             0.908254  \n",
       "std                          0.407097             0.100708  \n",
       "min                          0.000000             0.333333  \n",
       "25%                          0.000000             0.888889  \n",
       "50%                          0.500000             0.888889  \n",
       "75%                          1.000000             1.000000  \n",
       "max                          1.000000             1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_1 = \"Who was Jimmy Henson ?\"\n",
    "text_2 = \"Jim Henson was a puppeteer.\"\n",
    "\n",
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = tokenizer.encode(text_1, text_2, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['who', 'was', 'jimmy', 'henson', '?']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jim', 'henson', 'was', 'a', 'puppet', '##eer', '.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 2040,\n",
       " 1059,\n",
       " 3736,\n",
       " 5261,\n",
       " 27227,\n",
       " 1029,\n",
       " 102,\n",
       " 3958,\n",
       " 27227,\n",
       " 2001,\n",
       " 1037,\n",
       " 13997,\n",
       " 11510,\n",
       " 1012,\n",
       " 102]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jimmy'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.ids_to_tokens[5261]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_tensors = torch.tensor([segments_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2040,  2001,  5261, 27227,  1029,   102,  3958, 27227,  2001,\n",
       "          1037, 13997, 11510,  1012,   102]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentence A and B indices associated to 1st and 2nd sentences (see paper)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "# model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-uncased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4240,  0.2151, -0.8330,  ..., -1.0132,  0.7618,  0.6525],\n",
       "         [-0.7718, -0.2736, -0.5494,  ..., -0.0212,  0.7109, -0.2639],\n",
       "         [ 0.0835, -0.5506, -0.3897,  ..., -0.1108,  0.5886,  0.1662],\n",
       "         ...,\n",
       "         [-0.0454, -0.0224,  0.2818,  ...,  0.0837,  0.2598, -0.6440],\n",
       "         [ 0.6700,  0.1874, -0.4618,  ...,  0.2196, -0.4222, -0.2313],\n",
       "         [ 0.6586,  0.1840, -0.4281,  ...,  0.2181, -0.4304, -0.2145]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9933, -0.9174, -0.9997,  0.9896,  0.9854, -0.8039,  0.9979,  0.8225,\n",
       "         -0.9983, -1.0000, -0.9680,  0.9995,  0.9943,  0.9654,  0.9947, -0.9853,\n",
       "         -0.9559, -0.9154,  0.8017, -0.9606,  0.9685,  1.0000, -0.8347,  0.8349,\n",
       "          0.9031,  1.0000, -0.9850,  0.9872,  0.9923,  0.9129, -0.9775,  0.8169,\n",
       "         -0.9955, -0.7564, -0.9995, -0.9997,  0.9098, -0.9415, -0.7213, -0.7145,\n",
       "         -0.9831,  0.8563,  1.0000,  0.5766,  0.8930, -0.8394, -1.0000,  0.7998,\n",
       "         -0.9696,  0.9998,  0.9992,  0.9989,  0.8349,  0.9414,  0.9340, -0.9167,\n",
       "          0.6670,  0.7630, -0.7886, -0.9586, -0.9098,  0.8769, -0.9982, -0.9909,\n",
       "          0.9998,  0.9986, -0.8408, -0.8523, -0.8086,  0.7480,  0.9965,  0.7980,\n",
       "         -0.8701, -0.9587,  0.9971,  0.8546, -0.8908,  1.0000, -0.9342, -0.9952,\n",
       "          0.9980,  0.9985,  0.8919, -0.9880,  0.9890, -1.0000,  0.9610, -0.6543,\n",
       "         -0.9963,  0.8276,  0.9536, -0.8386,  0.9918,  0.9046, -0.9765, -0.9190,\n",
       "         -0.8987, -0.9978, -0.8567, -0.8842,  0.6871, -0.8234, -0.9412, -0.8290,\n",
       "          0.8681, -0.9284, -0.9393,  0.9100,  0.9382,  0.9508,  0.7541, -0.8625,\n",
       "          0.9271, -0.9938,  0.9563, -0.8599, -0.9956, -0.9008, -0.9971,  0.9516,\n",
       "         -0.9296, -0.8505,  0.9949, -0.9220,  0.8838, -0.8296, -0.9997, -1.0000,\n",
       "         -0.9578, -0.9501, -0.8059, -0.8784, -0.9918, -0.9891,  0.9620,  0.9875,\n",
       "          0.8537,  1.0000, -0.8669,  0.9861, -0.9364, -0.9890,  0.9866, -0.9446,\n",
       "          0.9845,  0.9457, -0.9767,  0.8320, -0.9003,  0.8822, -0.9892, -0.8464,\n",
       "         -0.9976, -0.9873, -0.8034,  0.9858, -0.9762, -0.9999, -0.9519, -0.8285,\n",
       "         -0.9219,  0.9725,  0.9737,  0.8962, -0.9299,  0.8975,  0.9831,  0.9386,\n",
       "         -0.9765, -0.8342,  0.9190, -0.8410, -0.9983, -0.9948, -0.9156,  0.9034,\n",
       "          0.9970,  0.9680,  0.8697,  0.9961, -0.8210,  0.9792, -0.9861,  0.9945,\n",
       "         -0.7716,  0.7104, -0.9672,  0.9315, -0.9809,  0.8680,  0.9946, -0.9768,\n",
       "         -0.9554, -0.8329, -0.8655, -0.8696, -0.9955,  0.9008, -0.8248, -0.8131,\n",
       "         -0.7697,  0.9778,  0.9998,  0.9728,  0.9705,  0.9442, -0.9933, -0.9047,\n",
       "          0.8009,  0.8113,  0.7451,  0.9987, -0.9674, -0.8046, -0.9863, -0.9960,\n",
       "          0.7464, -0.9821, -0.8336, -0.9536,  0.9848, -0.9294,  0.9899,  0.8617,\n",
       "         -0.9999, -0.9589,  0.8914, -0.9021,  0.9150, -0.7890,  0.8530,  0.9997,\n",
       "         -0.9483,  0.9907,  0.9642, -0.9994, -0.9381,  0.9921, -0.8726,  0.9913,\n",
       "         -0.9678,  0.9999,  0.9995,  0.9909, -0.9846, -0.9969, -0.9933, -0.9970,\n",
       "         -0.7420,  0.9730,  0.9998,  0.9401,  0.8846, -0.9429, -0.9540,  1.0000,\n",
       "         -0.9550, -0.9883, -0.8715, -0.8835, -0.9964,  0.9971,  0.8084,  0.9492,\n",
       "         -0.9342, -0.9806, -0.9918,  0.9961,  0.8358,  0.9998, -0.9146, -0.9982,\n",
       "         -0.9762, -0.9875,  0.7338, -0.8555, -0.9869,  0.5574, -0.9933,  0.9056,\n",
       "          0.8933,  0.9469, -0.9994,  1.0000,  1.0000,  0.9954,  0.9827,  0.9966,\n",
       "         -1.0000, -0.7945,  1.0000, -1.0000, -1.0000, -0.9916, -0.9773,  0.8513,\n",
       "         -1.0000, -0.7517, -0.7250, -0.9866,  0.9963,  0.9927,  1.0000, -1.0000,\n",
       "          0.9681,  0.9885, -0.9270,  0.9997, -0.9062,  0.9927,  0.9655,  0.8622,\n",
       "         -0.8272,  0.9074, -0.9999, -0.9958, -0.9938, -0.9953,  1.0000,  0.8304,\n",
       "         -0.9666, -0.9904,  0.9531, -0.7782,  0.7799, -0.9902, -0.8441,  0.9870,\n",
       "          0.9796,  0.7568,  0.8087, -0.9518,  0.8864,  0.8998,  0.9174,  0.8964,\n",
       "         -0.9873, -0.9225, -0.8680,  0.8167, -0.9950, -0.9897,  0.9965, -0.8894,\n",
       "          0.9992,  1.0000,  0.9390, -0.9931,  0.9533,  0.8758, -0.8942,  1.0000,\n",
       "          0.9815, -0.9913, -0.8824,  0.9522, -0.9696, -0.9725,  1.0000, -0.7956,\n",
       "         -0.9979, -0.9812,  0.9928, -0.9956,  1.0000, -0.9832, -0.9891,  0.9936,\n",
       "          0.9853, -0.9866, -0.8775,  0.8146, -0.9966,  0.8467, -0.9969,  0.9833,\n",
       "          0.9594, -0.7336,  0.9691, -0.9963, -0.8711,  0.8396, -0.9907, -0.9143,\n",
       "          0.9995,  0.9254, -0.7915,  0.6645, -0.8595, -0.8401, -0.9932,  0.9306,\n",
       "          1.0000, -0.9011,  0.9951, -0.9658, -0.6090,  0.7783,  0.9334,  0.9630,\n",
       "         -0.8572, -0.9840,  0.9949, -0.9996, -0.9957,  0.9809,  0.8302, -0.7857,\n",
       "          1.0000,  0.9553,  0.7887,  0.9167,  1.0000,  0.6972,  0.9356,  0.9998,\n",
       "          0.9936, -0.8168,  0.8929,  0.9935, -0.9999, -0.8647, -0.9325,  0.6160,\n",
       "         -0.9724, -0.7242, -0.9901,  0.9916,  0.9999,  0.9141,  0.8646,  0.9878,\n",
       "          1.0000, -0.8495,  0.9530, -0.9668,  0.9957, -1.0000, -0.9916, -0.8878,\n",
       "         -0.7975, -0.9992, -0.8515,  0.8378, -0.9928,  0.9992,  0.9845, -0.9999,\n",
       "         -0.9983, -0.9535,  0.9937,  0.7719, -1.0000, -0.9837, -0.8520,  0.9897,\n",
       "         -0.8955, -0.9920, -0.9621, -0.8954,  0.9082, -0.8332,  0.8517,  0.9993,\n",
       "         -0.7784, -0.9949, -0.8547, -0.7323, -0.9852,  0.9865, -0.9760, -0.9994,\n",
       "         -0.8001,  1.0000, -0.9189,  0.9995,  0.9650,  0.9803, -0.8372,  0.7163,\n",
       "          0.9992,  0.8501, -0.9992, -0.9998, -0.9929, -0.9056,  0.9281,  0.9910,\n",
       "          0.9965,  0.9661,  0.9866,  0.8476, -0.7717,  0.7554,  1.0000, -0.7822,\n",
       "         -0.8139, -0.9528, -0.7412, -0.8906, -0.9431,  1.0000,  0.8341,  0.9550,\n",
       "         -0.9966, -0.9981, -0.9973,  1.0000,  0.9625, -0.9681,  0.9683,  0.9497,\n",
       "         -0.8238,  0.9913, -0.8410, -0.8019,  0.8480,  0.8193,  0.9933, -0.9540,\n",
       "         -0.9900, -0.9466,  0.9270, -0.9943,  1.0000, -0.9586, -0.8472, -0.9058,\n",
       "         -0.8413,  0.9755,  0.5523, -0.9948, -0.8323,  0.8310,  0.9924,  0.7876,\n",
       "         -0.8930, -0.9796,  0.9990,  0.9973, -0.9996, -0.9833,  0.9911, -0.9967,\n",
       "          0.9329,  1.0000,  0.8649,  0.9468,  0.9035, -0.9127,  0.9321, -0.9408,\n",
       "          0.9778, -0.9938, -0.9104, -0.8289,  0.8921, -0.8394, -0.8515,  0.9378,\n",
       "          0.7197, -0.8723, -0.9595, -0.8495,  0.9103,  0.9951, -0.8001, -0.8147,\n",
       "          0.7336, -0.7713, -0.9975, -0.8852, -0.9179, -1.0000,  0.9563, -1.0000,\n",
       "          0.9699,  0.9605, -0.7867,  0.9661,  0.7957,  0.9854, -0.9720, -0.9996,\n",
       "         -0.9147,  0.9594, -0.9106, -0.9410, -0.9402,  0.9112, -0.8234,  0.7803,\n",
       "         -0.9773,  0.9488, -0.8563,  1.0000,  0.8358, -0.9683, -0.9999,  0.7644,\n",
       "         -0.8633,  1.0000, -0.9967, -0.9869,  0.8376, -0.9865, -0.9725,  0.8458,\n",
       "          0.6833, -0.9818, -0.9999,  0.9972,  0.9983, -0.7921,  0.9262, -0.8872,\n",
       "         -0.9309,  0.6665,  0.9990,  0.9960,  0.9725,  0.9957, -0.7346, -0.9060,\n",
       "          0.9938,  0.8401,  0.9581,  0.7553,  1.0000,  0.8694, -0.9803, -0.8547,\n",
       "         -0.9977, -0.8819, -0.9947,  0.8772,  0.8664,  0.9808, -0.8614,  0.9970,\n",
       "         -0.9986,  0.6877, -0.9731, -0.9926,  0.8639, -0.9873, -0.9958, -0.9959,\n",
       "          0.9572, -0.8597, -0.7612,  0.7696,  0.7462,  0.9274,  0.9021, -1.0000,\n",
       "          0.9870,  0.9136,  0.9997,  0.9895,  0.9839,  0.9231,  0.8238, -0.9965,\n",
       "         -0.9999, -0.8892, -0.8075,  0.9721,  0.9545,  0.9821,  0.9031, -0.8549,\n",
       "         -0.8758, -0.9922, -0.8941, -0.9974,  0.8867, -0.9948, -0.9994,  0.9897,\n",
       "          0.8991, -0.7574, -0.9438, -0.9951,  0.9989,  0.9811,  0.8966,  0.6867,\n",
       "          0.8838,  0.9877,  0.9960,  0.9947, -0.9990,  0.9849, -0.9919,  0.9038,\n",
       "          0.8833, -0.9821,  0.7933,  0.9333, -0.9500,  0.8361, -0.8271, -0.9996,\n",
       "          0.7948, -0.7809,  0.9482, -0.8622, -0.6932, -0.8912, -0.6668, -0.9478,\n",
       "         -0.9788,  0.8838,  0.9417,  0.9827,  0.9935, -0.7674, -0.9790, -0.7826,\n",
       "         -0.9984, -0.9790,  0.9990, -0.7784, -0.9777,  0.9913,  0.7086,  0.8878,\n",
       "          0.9326, -0.8790, -0.9073, -0.9705,  0.9894, -0.7704, -0.9515, -0.9643,\n",
       "          0.9564,  0.8139,  1.0000, -0.9986, -0.9997, -0.7929, -0.9021,  0.8379,\n",
       "         -0.9007, -1.0000,  0.8930, -0.9666,  0.9916, -0.9936,  0.9974, -0.9865,\n",
       "         -0.9998, -0.8850,  0.9483,  0.9969, -0.9244, -0.9687,  0.8770, -0.8892,\n",
       "          0.9999,  0.9757, -0.8988, -0.8899,  0.9232, -0.9971, -0.9548,  0.9918]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
